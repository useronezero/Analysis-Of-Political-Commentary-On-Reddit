{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d22272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20dd1c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "consrv_big = pd.read_csv(\"Conservative.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b3e7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "consrv_small = pd.read_csv(\"Conservatives.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46bbc745",
   "metadata": {},
   "outputs": [],
   "source": [
    "republic = pd.read_csv(\"Republican.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6074c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning big_consv first :P\n",
    "consrv_big_score_sorted = republic.sort_values(by='score',ascending=False)\n",
    "consrv_big_score_sorted_2k = consrv_big_score_sorted[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3585fee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>score</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>Breaking News: Amy Coney-Barrett says she spea...</td>\n",
       "      <td>1062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>Since Amy Coney Barrett is alive, can she fair...</td>\n",
       "      <td>742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>379</td>\n",
       "      <td>This letter is literally one of the most despi...</td>\n",
       "      <td>698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>1412</td>\n",
       "      <td>It’s because r/news , r/reddit, r/Christianity...</td>\n",
       "      <td>625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>1123</td>\n",
       "      <td>Gay here. Haven’t lost any rights yet, but I’m...</td>\n",
       "      <td>601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>6127</td>\n",
       "      <td>Wait, I'm confused. Is Trump a diabolical geni...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6903</th>\n",
       "      <td>6903</td>\n",
       "      <td>Knife fights are “normal” and “healthy” for te...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>2764</td>\n",
       "      <td>As a Wisconsin resident its frustrating being ...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>3047</td>\n",
       "      <td>I’m scared at how they think it’s ok to shoot ...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4921</th>\n",
       "      <td>4921</td>\n",
       "      <td>The \"Weekend at Bernie's\" image would be more ...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                            comment  score  \\\n",
       "170          170  Breaking News: Amy Coney-Barrett says she spea...   1062   \n",
       "171          171  Since Amy Coney Barrett is alive, can she fair...    742   \n",
       "379          379  This letter is literally one of the most despi...    698   \n",
       "1412        1412  It’s because r/news , r/reddit, r/Christianity...    625   \n",
       "1123        1123  Gay here. Haven’t lost any rights yet, but I’m...    601   \n",
       "...          ...                                                ...    ...   \n",
       "6127        6127  Wait, I'm confused. Is Trump a diabolical geni...     32   \n",
       "6903        6903  Knife fights are “normal” and “healthy” for te...     32   \n",
       "2764        2764  As a Wisconsin resident its frustrating being ...     32   \n",
       "3047        3047  I’m scared at how they think it’s ok to shoot ...     32   \n",
       "4921        4921  The \"Weekend at Bernie's\" image would be more ...     32   \n",
       "\n",
       "      type  \n",
       "170      0  \n",
       "171      0  \n",
       "379      0  \n",
       "1412     0  \n",
       "1123     0  \n",
       "...    ...  \n",
       "6127     0  \n",
       "6903     0  \n",
       "2764     0  \n",
       "3047     0  \n",
       "4921     0  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consrv_big_score_sorted_2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abfb9ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install clean-text\n",
    "#pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3c1f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "452f2e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clean(\"some input\",\\n    fix_unicode=True,               # fix various unicode errors\\n    to_ascii=True,                  # transliterate to closest ASCII representation\\n    lower=True,                     # lowercase text\\n    no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\\n    no_urls=False,                  # replace all URLs with a special token\\n    no_emails=False,                # replace all email addresses with a special token\\n    no_phone_numbers=False,         # replace all phone numbers with a special token\\n    no_numbers=False,               # replace all numbers with a special token\\n    no_digits=False,                # replace all digits with a special token\\n    no_currency_symbols=False,      # replace all currency symbols with a special token\\n    no_punct=False,                 # remove punctuations\\n    replace_with_punct=\"\",          # instead of removing punctuations you may replace them\\n    replace_with_url=\"<URL>\",\\n    replace_with_email=\"<EMAIL>\",\\n    replace_with_phone_number=\"<PHONE>\",\\n    replace_with_number=\"<NUMBER>\",\\n    replace_with_digit=\"0\",\\n    replace_with_currency_symbol=\"<CUR>\",\\n    lang=\"en\"                       # set to \\'de\\' for German special handling\\n) '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reference\n",
    "'''clean(\"some input\",\n",
    "    fix_unicode=True,               # fix various unicode errors\n",
    "    to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "    lower=True,                     # lowercase text\n",
    "    no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n",
    "    no_urls=False,                  # replace all URLs with a special token\n",
    "    no_emails=False,                # replace all email addresses with a special token\n",
    "    no_phone_numbers=False,         # replace all phone numbers with a special token\n",
    "    no_numbers=False,               # replace all numbers with a special token\n",
    "    no_digits=False,                # replace all digits with a special token\n",
    "    no_currency_symbols=False,      # replace all currency symbols with a special token\n",
    "    no_punct=False,                 # remove punctuations\n",
    "    replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "    replace_with_url=\"<URL>\",\n",
    "    replace_with_email=\"<EMAIL>\",\n",
    "    replace_with_phone_number=\"<PHONE>\",\n",
    "    replace_with_number=\"<NUMBER>\",\n",
    "    replace_with_digit=\"0\",\n",
    "    replace_with_currency_symbol=\"<CUR>\",\n",
    "    lang=\"en\"                       # set to 'de' for German special handling\n",
    ") '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3ed378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower casing and unicode fix\n",
    "cleaned_comments = []\n",
    "for comment in consrv_big_score_sorted_2k.comment :\n",
    "    tempdict = {}\n",
    "    clean_comment = clean(comment,\n",
    "    fix_unicode=True,               # fix various unicode errors\n",
    "    lower=True,                     # lowercase text\n",
    "    no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "    no_urls=True,                  # replace all URLs with a special token\n",
    "    no_emails=True,                # replace all email addresses with a special token\n",
    "    no_phone_numbers=True,         # replace all phone numbers with a special token\n",
    "    no_numbers=True,               # replace all numbers with a special token\n",
    "    no_digits=True,                # replace all digits with a special token\n",
    "    no_currency_symbols=True,\n",
    "    no_punct=True,                      # remove punctuations\n",
    "    replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "    replace_with_url=\"\",\n",
    "    replace_with_email=\"\",\n",
    "    replace_with_phone_number=\"\",\n",
    "    replace_with_number=\"\",\n",
    "    replace_with_digit=\"\",\n",
    "    replace_with_currency_symbol=\"\",\n",
    "    lang=\"en\")\n",
    "    tempdict[\"comment\"]=clean_comment\n",
    "    cleaned_comments.append(tempdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c6cb859",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_1_df = pd.DataFrame(cleaned_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b989fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e4a0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "clean_1_df['comment'] = clean_1_df['comment'].apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d03dda7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, lxml\n",
    "\n",
    "def spellcorrect(word):\n",
    "    headers = {\n",
    "        'User-agent':\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.19582\"\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "      'q': word,\n",
    "      'hl': 'en',\n",
    "      'gl': 'us',\n",
    "    }\n",
    "\n",
    "    html = requests.get('https://www.google.com/search?q=', headers=headers, params=params).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    try :\n",
    "      corrected_word = soup.select_one('a.gL9Hy').text\n",
    "\n",
    "      corrected_word_link = f\"https://www.google.com{soup.select_one('a.gL9Hy')['href']}\"\n",
    "      search_instead_for = soup.select_one('a.spell_orig').text\n",
    "      search_instead_for_link = f\"https://www.google.com{soup.select_one('a.spell_orig')['href']}\"\n",
    "      print(f'{corrected_word}')\n",
    "    except:\n",
    "      pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff7d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8c5ce59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6e911c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_1_df_with_stop_words = clean_1_df.copy()\n",
    "clean_1_df['comment'] = clean_1_df['comment'].apply(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "eef7af0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('people', 410),\n",
       " ('like', 313),\n",
       " ('dont', 270),\n",
       " ('trump', 244),\n",
       " ('im', 185),\n",
       " ('would', 176),\n",
       " ('think', 174),\n",
       " ('get', 163),\n",
       " ('one', 156),\n",
       " ('us', 151),\n",
       " ('see', 139),\n",
       " ('biden', 130),\n",
       " ('left', 127),\n",
       " ('right', 126),\n",
       " ('even', 118),\n",
       " ('democrats', 117),\n",
       " ('know', 114),\n",
       " ('want', 107),\n",
       " ('going', 105),\n",
       " ('time', 104)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for text in clean_1_df['comment'].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "        \n",
    "cnt.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ad7a0bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from textblob import TextBlob\n",
    "#clean_1_df['comment'] = clean_1_df['comment'].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7336c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "410bf265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lemmatization is the process of converting a word to its base form. \\nThe difference between stemming and lemmatization is, \\nlemmatization considers the context and converts the word to its meaningful base form,\\nwhereas stemming just removes the last few characters, often leading to incorrect\\nmeanings and spelling errors. Here, lemmatization only performed. We need to provide \\nthe POS tag of the word along with the word for lemmatizer in NLTK. Depending on the POS, \\nthe lemmatizer may return different results.'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Lemmatization is the process of converting a word to its base form. \n",
    "The difference between stemming and lemmatization is, \n",
    "lemmatization considers the context and converts the word to its meaningful base form,\n",
    "whereas stemming just removes the last few characters, often leading to incorrect\n",
    "meanings and spelling errors. Here, lemmatization only performed. We need to provide \n",
    "the POS tag of the word along with the word for lemmatizer in NLTK. Depending on the POS, \n",
    "the lemmatizer may return different results.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c1c35ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV} # Pos tag, used Noun, Verb, Adjective and Adverb\n",
    "# Function for lemmatization using POS tag\n",
    "def lemmatize_words(text):\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "clean_1_df['comment'] = clean_1_df['comment'].apply(lemmatize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "089bed6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [break, news, amy, coneybarrett, say, speaks, ...\n",
       "1    [since, amy, coney, barrett, alive, fairly, ru...\n",
       "2    [letter, literally, one, despicable, thing, iv...\n",
       "3    [rnews, rreddit, rchristianity, pretty, much, ...\n",
       "4    [gay, havent, lose, right, yet, im, really, en...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenisization\n",
    "\n",
    "#Creating function for tokenization\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "# Passing the function to 'text_rare' and store into'text_token'\n",
    "clean_1_df['comment'] = clean_1_df['comment'].apply(lambda x: tokenization(x.lower()))\n",
    "clean_1_df['comment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c1cbf95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_1_df.to_csv(\"conservative-big-2k-toekns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0c489587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_1_df.to_csv(\"conservative-small-2k-toekns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bb444aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_1_df.to_csv(\"republic-2k-toekns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7634f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, lxml\n",
    "\n",
    "def spellcorrect(word):\n",
    "    headers = {\n",
    "        'User-agent':\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.19582\"\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "      'q': word,\n",
    "      'hl': 'en',\n",
    "      'gl': 'us',\n",
    "    }\n",
    "\n",
    "    html = requests.get('https://www.google.com/search?q=', headers=headers, params=params).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    try :\n",
    "          corrected_word = soup.select_one('a.gL9Hy').text\n",
    "\n",
    "          corrected_word_link = f\"https://www.google.com{soup.select_one('a.gL9Hy')['href']}\"\n",
    "          search_instead_for = soup.select_one('a.spell_orig').text\n",
    "          search_instead_for_link = f\"https://www.google.com{soup.select_one('a.spell_orig')['href']}\"\n",
    "          \n",
    "    except:\n",
    "          return word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a530e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_list = []\n",
    "for comment in clean_1_df['comment'].head(5):\n",
    "  \n",
    "  com = spellcorrect(comment)\n",
    "  comment_list.append(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aecbb633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breaking news amy coneybarrett says she speaks but could fairly judge a case on free speech',\n",
       " 'since amy coney barrett is alive can she fairly rule on a capital murder case',\n",
       " \"this letter is literally one of the most despicable things i've ever seen\",\n",
       " 'its because rnews reddit christianity and pretty much everywhere else is democrats',\n",
       " 'gay here havent lost any rights yet but im really enjoying my lower taxes and my rent hasnt gone up in years']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb7c81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
