{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d22272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20dd1c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberal = pd.read_csv(\"Liberal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3e7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "socialism = pd.read_csv(\"socialism.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46bbc745",
   "metadata": {},
   "outputs": [],
   "source": [
    "progressive = pd.read_csv(\"progressive.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe2665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "democrat = pd.read_csv(\"democrats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "638b14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_set = pd.read_csv(\"Right_meme_set_1050.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "31e8dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_set = pd.read_csv(\"Left_meme_set_724.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8af8408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6074c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning big_consv first :P\n",
    "consrv_big_score_sorted = democrat.sort_values(by='score',ascending=False)\n",
    "consrv_big_score_sorted_2k = consrv_big_score_sorted[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3585fee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>score</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>McConnell blocked Merrick Garland's nomination...</td>\n",
       "      <td>1311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>160</td>\n",
       "      <td>when dems actually whoop some ass, for once, l...</td>\n",
       "      <td>811</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>3138</td>\n",
       "      <td>Texas turning blue this year and staying blue ...</td>\n",
       "      <td>653</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Republicans: *\"WhY aReN'T yOu PrAcTiCiNg UnItY...</td>\n",
       "      <td>569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>1466</td>\n",
       "      <td>LOL!  He is just figuring that out now?!?!  ho...</td>\n",
       "      <td>541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>1183</td>\n",
       "      <td>The Jewish guy in the back is about to start f...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>1965</td>\n",
       "      <td>To be fair, they knew Trump didn't have the mo...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7657</th>\n",
       "      <td>7657</td>\n",
       "      <td>IMO Democrats need to go Nuclear on two items,...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7666</th>\n",
       "      <td>7666</td>\n",
       "      <td>It’s like the Republican base has the long ter...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6109</th>\n",
       "      <td>6109</td>\n",
       "      <td>What is worse. The man who deigns to sign a bi...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                            comment  score  \\\n",
       "0              0  McConnell blocked Merrick Garland's nomination...   1311   \n",
       "160          160  when dems actually whoop some ass, for once, l...    811   \n",
       "3138        3138  Texas turning blue this year and staying blue ...    653   \n",
       "2              2  Republicans: *\"WhY aReN'T yOu PrAcTiCiNg UnItY...    569   \n",
       "1466        1466  LOL!  He is just figuring that out now?!?!  ho...    541   \n",
       "...          ...                                                ...    ...   \n",
       "1183        1183  The Jewish guy in the back is about to start f...     27   \n",
       "1965        1965  To be fair, they knew Trump didn't have the mo...     27   \n",
       "7657        7657  IMO Democrats need to go Nuclear on two items,...     27   \n",
       "7666        7666  It’s like the Republican base has the long ter...     27   \n",
       "6109        6109  What is worse. The man who deigns to sign a bi...     27   \n",
       "\n",
       "      type  \n",
       "0        0  \n",
       "160      0  \n",
       "3138     0  \n",
       "2        0  \n",
       "1466     0  \n",
       "...    ...  \n",
       "1183     0  \n",
       "1965     0  \n",
       "7657     0  \n",
       "7666     0  \n",
       "6109     0  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consrv_big_score_sorted_2k\n",
    "\n",
    "#consrv_big_score_sorted_2k = left_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abfb9ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install clean-text\n",
    "#pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3c1f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "452f2e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clean(\"some input\",\\n    fix_unicode=True,               # fix various unicode errors\\n    to_ascii=True,                  # transliterate to closest ASCII representation\\n    lower=True,                     # lowercase text\\n    no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\\n    no_urls=False,                  # replace all URLs with a special token\\n    no_emails=False,                # replace all email addresses with a special token\\n    no_phone_numbers=False,         # replace all phone numbers with a special token\\n    no_numbers=False,               # replace all numbers with a special token\\n    no_digits=False,                # replace all digits with a special token\\n    no_currency_symbols=False,      # replace all currency symbols with a special token\\n    no_punct=False,                 # remove punctuations\\n    replace_with_punct=\"\",          # instead of removing punctuations you may replace them\\n    replace_with_url=\"<URL>\",\\n    replace_with_email=\"<EMAIL>\",\\n    replace_with_phone_number=\"<PHONE>\",\\n    replace_with_number=\"<NUMBER>\",\\n    replace_with_digit=\"0\",\\n    replace_with_currency_symbol=\"<CUR>\",\\n    lang=\"en\"                       # set to \\'de\\' for German special handling\\n) '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reference\n",
    "'''clean(\"some input\",\n",
    "    fix_unicode=True,               # fix various unicode errors\n",
    "    to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "    lower=True,                     # lowercase text\n",
    "    no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n",
    "    no_urls=False,                  # replace all URLs with a special token\n",
    "    no_emails=False,                # replace all email addresses with a special token\n",
    "    no_phone_numbers=False,         # replace all phone numbers with a special token\n",
    "    no_numbers=False,               # replace all numbers with a special token\n",
    "    no_digits=False,                # replace all digits with a special token\n",
    "    no_currency_symbols=False,      # replace all currency symbols with a special token\n",
    "    no_punct=False,                 # remove punctuations\n",
    "    replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "    replace_with_url=\"<URL>\",\n",
    "    replace_with_email=\"<EMAIL>\",\n",
    "    replace_with_phone_number=\"<PHONE>\",\n",
    "    replace_with_number=\"<NUMBER>\",\n",
    "    replace_with_digit=\"0\",\n",
    "    replace_with_currency_symbol=\"<CUR>\",\n",
    "    lang=\"en\"                       # set to 'de' for German special handling\n",
    ") '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3ed378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower casing and unicode fix\n",
    "cleaned_comments = []\n",
    "for comment in consrv_big_score_sorted_2k.comment :\n",
    "    tempdict = {}\n",
    "    clean_comment = clean(comment,\n",
    "    fix_unicode=True,               # fix various unicode errors\n",
    "    lower=True,                     # lowercase text\n",
    "    no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "    no_urls=True,                  # replace all URLs with a special token\n",
    "    no_emails=True,                # replace all email addresses with a special token\n",
    "    no_phone_numbers=True,         # replace all phone numbers with a special token\n",
    "    no_numbers=True,               # replace all numbers with a special token\n",
    "    no_digits=True,                # replace all digits with a special token\n",
    "    no_currency_symbols=True,\n",
    "    no_punct=True,                      # remove punctuations\n",
    "    replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "    replace_with_url=\"\",\n",
    "    replace_with_email=\"\",\n",
    "    replace_with_phone_number=\"\",\n",
    "    replace_with_number=\"\",\n",
    "    replace_with_digit=\"\",\n",
    "    replace_with_currency_symbol=\"\",\n",
    "    lang=\"en\")\n",
    "    tempdict[\"comment\"]=clean_comment\n",
    "    cleaned_comments.append(tempdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c6cb859",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_1_df = pd.DataFrame(cleaned_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b989fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e4a0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_1_df['comment'] = clean_1_df['comment'].apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03dda7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c5ce59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def stopwords(text):\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e911c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_1_df['comment'] = clean_1_df['comment'].apply(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eef7af0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 362),\n",
       " ('people', 324),\n",
       " ('like', 278),\n",
       " ('would', 228),\n",
       " ('dont', 226),\n",
       " ('get', 209),\n",
       " ('republicans', 206),\n",
       " ('one', 176),\n",
       " ('im', 163),\n",
       " ('think', 138),\n",
       " ('biden', 135),\n",
       " ('vote', 135),\n",
       " ('even', 133),\n",
       " ('know', 130),\n",
       " ('republican', 127),\n",
       " ('time', 122),\n",
       " ('going', 114),\n",
       " ('need', 112),\n",
       " ('really', 109),\n",
       " ('us', 108)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for text in clean_1_df['comment'].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "        \n",
    "cnt.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad7a0bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from textblob import TextBlob\n",
    "#clean_1_df['comment'] = clean_1_df['comment'].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7336c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "410bf265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lemmatization is the process of converting a word to its base form. \\nThe difference between stemming and lemmatization is, \\nlemmatization considers the context and converts the word to its meaningful base form,\\nwhereas stemming just removes the last few characters, often leading to incorrect\\nmeanings and spelling errors. Here, lemmatization only performed. We need to provide \\nthe POS tag of the word along with the word for lemmatizer in NLTK. Depending on the POS, \\nthe lemmatizer may return different results.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Lemmatization is the process of converting a word to its base form. \n",
    "The difference between stemming and lemmatization is, \n",
    "lemmatization considers the context and converts the word to its meaningful base form,\n",
    "whereas stemming just removes the last few characters, often leading to incorrect\n",
    "meanings and spelling errors. Here, lemmatization only performed. We need to provide \n",
    "the POS tag of the word along with the word for lemmatizer in NLTK. Depending on the POS, \n",
    "the lemmatizer may return different results.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1c35ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV} \n",
    "# Pos tag, used Noun, Verb, Adjective and Adverb\n",
    "# Function for lemmatization using POS tag\n",
    "def lemmatize_words(text):\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "clean_1_df['comment'] = clean_1_df['comment'].apply(lemmatize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "089bed6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [mcconnell, block, merrick, garland, nominatio...\n",
       "1    [dems, actually, whoop, ass, let, know, cause,...\n",
       "2    [texas, turn, blue, year, stay, blue, two, dif...\n",
       "3    [republican, arent, practice, unity, everyone,...\n",
       "4                   [lol, figure, stupid, one, person]\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenisization\n",
    "\n",
    "#Creating function for tokenization\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "# Passing the function to 'text_rare' and store into'text_token'\n",
    "clean_1_df['comment'] = clean_1_df['comment'].apply(lambda x: tokenization(x.lower()))\n",
    "clean_1_df['comment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "490be199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[mcconnell, block, merrick, garland, nominatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[dems, actually, whoop, ass, let, know, cause,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[texas, turn, blue, year, stay, blue, two, dif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[republican, arent, practice, unity, everyone,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[lol, figure, stupid, one, person]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>[jewish, guy, back, start, fire, space, lazer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>[fair, know, trump, didnt, money, pay, anyway]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>[imo, democrat, need, go, nuclear, two, item, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>[like, republican, base, long, term, memory, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>[bad, man, deign, sign, bible, person, asks, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment\n",
       "0     [mcconnell, block, merrick, garland, nominatio...\n",
       "1     [dems, actually, whoop, ass, let, know, cause,...\n",
       "2     [texas, turn, blue, year, stay, blue, two, dif...\n",
       "3     [republican, arent, practice, unity, everyone,...\n",
       "4                    [lol, figure, stupid, one, person]\n",
       "...                                                 ...\n",
       "1995     [jewish, guy, back, start, fire, space, lazer]\n",
       "1996     [fair, know, trump, didnt, money, pay, anyway]\n",
       "1997  [imo, democrat, need, go, nuclear, two, item, ...\n",
       "1998  [like, republican, base, long, term, memory, g...\n",
       "1999  [bad, man, deign, sign, bible, person, asks, s...\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1cbf95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_1_df.to_csv(\"conservative-big-2k-toekns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c489587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_1_df.to_csv(\"conservative-small-2k-toekns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb444aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_1_df.to_csv(\"republic-2k-toekns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7634f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_1_df.to_csv(\"liberal-2k-tokens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "659b7da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_1_df.to_csv(\"socialism-2k-tokens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f0f7ac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_1_df.to_csv(\"progressive-2k-tokens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d0121a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_1_df.to_csv(\"right-meme-1050-tokens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "671f16f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_1_df.to_csv(\"left-meme-724-tokens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39144ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_1_df.to_csv(\"democrat-2k-tokens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96365ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
